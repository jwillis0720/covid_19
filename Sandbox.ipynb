{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import COVID19Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_api_json(json, source):\n",
    "    for_pandas = []\n",
    "    confirmed = []\n",
    "    deaths = []\n",
    "    recovered = []\n",
    "    for location in json['locations']:\n",
    "        timeline_entry = {}\n",
    "        entry = {\n",
    "            'id': location['id'],\n",
    "            'lat': location['coordinates']['latitude'],\n",
    "            'lon': location['coordinates']['longitude'],\n",
    "            'Date': pandas.to_datetime(location['last_updated']),\n",
    "            'province': location['province'],\n",
    "            'country_code': location['country_code'],\n",
    "            'country': location['country'],\n",
    "            'confirmed': location['latest']['confirmed'],\n",
    "            'deaths': location['latest']['deaths'],\n",
    "            'recovered': location['latest']['recovered'],\n",
    "            'county': ''}\n",
    "        if 'county' in location.keys():\n",
    "            entry['county'] = location['county']\n",
    "        if 'state' in location.keys():\n",
    "            entry['state'] = location['state']\n",
    "        entry['source'] = source\n",
    "        for_pandas.append(entry)\n",
    "\n",
    "        if 'timelines' in location.keys():\n",
    "            for status in location['timelines']:\n",
    "                for date in location['timelines'][status]['timeline']:\n",
    "                    sub_entry = {'id': location['id'],\n",
    "                                 'Date': pandas.to_datetime(date),\n",
    "                                 status: location['timelines'][status]['timeline'][date]}\n",
    "                    if status == 'confirmed':\n",
    "                        confirmed.append(sub_entry)\n",
    "                    elif status == 'deaths':\n",
    "                        deaths.append(sub_entry)\n",
    "                    else:\n",
    "                        recovered.append(sub_entry)\n",
    "    if confirmed:\n",
    "        # return confirmed,deaths,recovered\n",
    "        timeline_df = pandas.DataFrame(confirmed)\n",
    "        if deaths:\n",
    "            timeline_df = timeline_df.merge(\n",
    "                pandas.DataFrame(deaths), on=['id', 'Date'])\n",
    "        else:\n",
    "            timeline_df['deaths'] = 0\n",
    "        if recovered:\n",
    "            timeline_df = timeline_df.merge(\n",
    "                pandas.DataFrame(recovered), on=['id', 'Date'])\n",
    "        else:\n",
    "            timeline_df['recovered'] = 0.0\n",
    "\n",
    "        main_df = pandas.DataFrame(for_pandas)\n",
    "        timeline_df = timeline_df.merge(\n",
    "            main_df[['id', 'lat', 'lon', 'province', 'country_code', 'country', 'source']], on=['id'])\n",
    "\n",
    "        return main_df, timeline_df\n",
    "    else:\n",
    "        return pandas.DataFrame(for_pandas)\n",
    "\n",
    "covid19_csbs = COVID19Py.COVID19(data_source=\"csbs\").getAll(timelines=True)\n",
    "covid19_jhu = COVID19Py.COVID19(data_source=\"jhu\").getAll(timelines=True)\n",
    "jhu_df, jhu_df_time = parse_api_json(covid19_jhu, 'JHU')\n",
    "csbs_df = parse_api_json(covid19_csbs, 'CSBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = jhu_df_time[jhu_df_time[group] != '']\n",
    "province_mapper = sub_df[\n",
    "    sub_df['Date'] == official_date].groupby(\n",
    "        group, as_index=False).apply(lambda x: x.sort_values('confirmed')[::-1].head(1)[[group, 'id', 'lat', 'lon']])\n",
    "sub_df = sub_df[\n",
    "    sub_df['Date'] == official_date].groupby(group, as_index=False).sum()[['province', 'confirmed', 'deaths', 'recovered']].merge(province_mapper, on=['province'])\n",
    "\n",
    "##Now do it for the CSBS\n",
    "province_mapper = csbs_df.groupby(\n",
    "        group, as_index=False).apply(lambda x: x.sort_values('confirmed')[::-1].head(1)[[group, 'id', 'lat', 'lon']])\n",
    "sub_df_csbs = csbs_df.groupby(group, as_index=False).sum()[['province', 'confirmed', 'deaths', 'recovered']].merge(province_mapper, on=['province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_day_stats_by_state = pd.read_csv(\n",
    "    'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/provence_df_per_day.csv.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from S3:\n",
    "jhu_df = pd.read_csv(\n",
    "    'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/jhu_df.csv.gz', index_col=0)\n",
    "jhu_df_time = pd.read_csv(\n",
    "    'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/jhu_df_time.csv.gz', index_col=0)\n",
    "csbs_df = pd.read_csv(\n",
    "    'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/csbs_df.csv.gz', index_col=0)\n",
    "per_day_stats_by_country = pd.read_csv(\n",
    "    'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/country_df_per_day.csv.gz', index_col=0)\n",
    "per_day_stats_by_state = pd.read_csv(\n",
    "    'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/provence_df_per_day.csv.gz', index_col=0)\n",
    "\n",
    "jhu_df_time['Date'] = pd.to_datetime(jhu_df_time['Date'])\n",
    "jhu_df['Date'] = pd.to_datetime(jhu_df['Date'])\n",
    "csbs_df['Date'] = pd.to_datetime(csbs_df['Date'])\n",
    "\n",
    "date_mapper = pd.DataFrame(\n",
    "    jhu_df_time['Date'].unique(), columns=['Date'])\n",
    "date_mapper['Date_text'] = date_mapper['Date'].dt.strftime('%m/%d/%y')\n",
    "min_date = date_mapper.index[0]\n",
    "max_date = date_mapper.index[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_date = date_mapper.iloc[-1]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "\n",
    "official_date.date() == date.today() - timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.date' has no attribute 'yesterday'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-11935f3d8d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myesterday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'datetime.date' has no attribute 'yesterday'"
     ]
    }
   ],
   "source": [
    "date.yesterday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_date = date_mapper['Date'].iloc[-1]\n",
    "country_mapper = jhu_df_time[jhu_df_time['Date'] == official_date].groupby(\n",
    "    'country', as_index=False).apply(lambda x: x.sort_values('confirmed')[::-1].head(1)[['country', 'id', 'lat', 'lon']])\n",
    "sub_df = jhu_df_time[jhu_df_time['Date'] == official_date].groupby(\n",
    "    'country', as_index=False).sum().merge(country_mapper, on=['country'])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "group='province'\n",
    "sub_df = jhu_df_time[jhu_df_time[group] != '']\n",
    "province_mapper = sub_df[\n",
    "    sub_df['Date'] == official_date].groupby(\n",
    "        group, as_index=False).apply(lambda x: x.sort_values('confirmed')[::-1].head(1)[[group, 'id', 'lat', 'lon']])\n",
    "sub_df = sub_df[\n",
    "    sub_df['Date'] == official_date].groupby(group, as_index=False).sum()[['province', 'confirmed', 'deaths', 'recovered']].merge(province_mapper, on=['province'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13950    NaN\n",
       "13951    NaN\n",
       "13952    NaN\n",
       "13953    NaN\n",
       "13954    NaN\n",
       "        ... \n",
       "14007    NaN\n",
       "14008    NaN\n",
       "14009    NaN\n",
       "14010    NaN\n",
       "14011    NaN\n",
       "Name: province, Length: 62, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jhu_df_time[jhu_df_time['country'] == 'US']['province']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import COVID19Py\n",
    "import pandas\n",
    "\n",
    "# Cancel copy warnings of pandas\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=pd.core.common.SettingWithCopyWarning)\n",
    "\n",
    "\n",
    "covid19_csbs = COVID19Py.COVID19(data_source=\"csbs\").getAll(timelines=True)\n",
    "covid19_jhu = COVID19Py.COVID19(data_source=\"jhu\").getAll(timelines=True)\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(\n",
    "            file_name, bucket, object_name,  ExtraArgs={'ACL': 'public-read'})\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def parse_api_json(json, source):\n",
    "    for_pandas = []\n",
    "    confirmed = []\n",
    "    deaths = []\n",
    "    recovered = []\n",
    "    for location in json['locations']:\n",
    "        timeline_entry = {}\n",
    "        entry = {\n",
    "            'id': location['id'],\n",
    "            'lat': location['coordinates']['latitude'],\n",
    "            'lon': location['coordinates']['longitude'],\n",
    "            'Date': pandas.to_datetime(location['last_updated']),\n",
    "            'province': location['province'],\n",
    "            'country_code': location['country_code'],\n",
    "            'country': location['country'],\n",
    "            'cases': location['latest']['confirmed'],\n",
    "            'deaths': location['latest']['deaths'],\n",
    "            'recovered': location['latest']['recovered'],\n",
    "            'county': ''}\n",
    "        if 'county' in location.keys():\n",
    "            entry['county'] = location['county']\n",
    "        if 'state' in location.keys():\n",
    "            entry['state'] = location['state']\n",
    "        entry['source'] = source\n",
    "        for_pandas.append(entry)\n",
    "\n",
    "        if 'timelines' in location.keys():\n",
    "            for status in location['timelines']:\n",
    "                for date in location['timelines'][status]['timeline']:\n",
    "                    sub_entry = {'id': location['id'],\n",
    "                                 'Date': pandas.to_datetime(date),\n",
    "                                 status: location['timelines'][status]['timeline'][date]}\n",
    "                    if status == 'confirmed':\n",
    "                        confirmed.append(sub_entry)\n",
    "                    elif status == 'deaths':\n",
    "                        deaths.append(sub_entry)\n",
    "                    else:\n",
    "                        recovered.append(sub_entry)\n",
    "    if confirmed:\n",
    "        #return confirmed,deaths,recovered\n",
    "        timeline_df = pandas.DataFrame(confirmed)\n",
    "        if deaths:\n",
    "            timeline_df = timeline_df.merge(\n",
    "                pandas.DataFrame(deaths), on=['id', 'Date'])\n",
    "        else:\n",
    "            timeline_df['deaths'] = 0\n",
    "        if recovered:\n",
    "            timeline_df = timeline_df.merge(\n",
    "                pandas.DataFrame(recovered), on=['id', 'Date'])\n",
    "        else:\n",
    "            timeline_df['recovered'] = 0.0\n",
    "        \n",
    "        main_df = pandas.DataFrame(for_pandas)\n",
    "        timeline_df = timeline_df.merge(\n",
    "            main_df[['id', 'lat', 'lon', 'province', 'country_code', 'country', 'source']], on=['id'])\n",
    "\n",
    "        return main_df, timeline_df\n",
    "    else:\n",
    "        return pandas.DataFrame(for_pandas)\n",
    "    \n",
    "jhu_df, jhu_df_time = parse_api_json(covid19_jhu, 'JHU')\n",
    "csbs_df = parse_api_json(covid19_csbs, 'CSBS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_jhu['locations'][0]['latest']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_jhu['locations'][0]['timelines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import COVID19Py\n",
    "\n",
    "covid19_csbs = COVID19Py.COVID19(data_source=\"csbs\").getAll(timelines=True)\n",
    "covid19_jhu = COVID19Py.COVID19(data_source=\"jhu\").getAll(timelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_jhu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [i.keys() for i in covid19_csbs['locations']]:\n",
    "    if \"timelines\" in i:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_df[jhu_df['province'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_jhu['locations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "URL = \"https://coronavirus-tracker-api.herokuapp.com/\"\n",
    "LOCATIONS_COUNTRY = \"v2/locations?timelines=1\"\n",
    "LOCATIONS_COUNTY = \"v2/locations?timelines=1&source=csbs\"\n",
    "\n",
    "locations_county = requests.get(URL+LOCATIONS_COUNTY).json()\n",
    "#locations_country = requests.get(URL+LOCATIONS_COUNTRY).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api_json(json,source):\n",
    "    for_pandas = []\n",
    "    confirmed = []\n",
    "    deaths = []\n",
    "    recovered = []\n",
    "    for location in json['locations']:\n",
    "        timeline_entry = {}\n",
    "        entry = {\n",
    "            'id':location['id'],\n",
    "            'lat':location['coordinates']['latitude'],\n",
    "            'lon':location['coordinates']['longitude'],\n",
    "            'Date':pandas.to_datetime(location['last_updated']),\n",
    "            'province':location['province'],\n",
    "            'country_code': location['country_code'],\n",
    "            'country': location['country'] ,\n",
    "            'cases':location['latest']['confirmed'],\n",
    "            'deaths':location['latest']['deaths'],\n",
    "            'recovered':location['latest']['recovered'],\n",
    "            'county':''}\n",
    "        if 'county' in location.keys():\n",
    "            entry['county'] = location['county']\n",
    "        if 'state' in location.keys():\n",
    "            entry['state'] = location['state']\n",
    "        entry['source'] = source\n",
    "        for_pandas.append(entry)\n",
    "        \n",
    "        if 'timelines' in location.keys():\n",
    "            for status in location['timelines']:\n",
    "                for date in location['timelines'][status]['timeline']: \n",
    "                        sub_entry = {'id':location['id'],\n",
    "                                     'Date':pandas.to_datetime(date),\n",
    "                                     status:location['timelines'][status]['timeline'][date]}\n",
    "                        if status ==  'confirmed':\n",
    "                            confirmed.append(sub_entry)\n",
    "                        elif status == 'deaths':\n",
    "                            deaths.append(sub_entry)\n",
    "                        else:\n",
    "                            recovered.append(sub_entry)\n",
    "    if confirmed:\n",
    "        timeline_df = pandas.DataFrame(confirmed).merge(\n",
    "            pandas.DataFrame(deaths),on=['id','Date']).merge(\n",
    "            pandas.DataFrame(recovered), on=['id','Date'])\n",
    "        main_df = pandas.DataFrame(for_pandas)\n",
    "        timeline_df = timeline_df.merge(main_df[['id','lat','lon','province','country_code','country','source']],on=['id'])\n",
    "        \n",
    "        return main_df,timeline_df\n",
    "    else:\n",
    "        return pandas.DataFrame(for_pandas)\n",
    "    \n",
    "jhu_df,jhu_df_time = parse_api_json(covid19_jhu,'JHU')\n",
    "csbs_df = parse_api_json(covid19_csbs,'CSBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = pandas\n",
    "date_mapper = pd.DataFrame(\n",
    "    jhu_df_time['Date'].unique(), columns=['Date'])\n",
    "date_mapper['Date_text'] = date_mapper['Date'].dt.strftime('%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_mapper.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_x_cases(grouper,df):\n",
    "    new_cases_by_country = []\n",
    "    dates = date_mapper['Date']\n",
    "    sub_group = df[df[grouper] != \"\"]\n",
    "    groupers = sub_group[grouper].unique()\n",
    "\n",
    "    for group in groupers:\n",
    "        sub_country = sub_group[sub_group[grouper] == group]\n",
    "        new_cases_by_country.append(\n",
    "            {grouper: group, 'Date': dates[0],\n",
    "             'New Cases': sub_country.loc[sub_country['Date'] == dates[0], 'confirmed'].sum(),\n",
    "             'New Deaths': 0,\n",
    "             'New Recovery': 0})\n",
    "        for date_index in range(1, len(dates)):\n",
    "            current_date = dates[date_index]\n",
    "            day_before = dates[date_index-1]\n",
    "            # print(current_date,day_before)\n",
    "            t_c, t_d, t_r = sub_country.loc[sub_country['Date']\n",
    "                                            == current_date, :].sum()[['confirmed', 'deaths', 'recovered']]\n",
    "\n",
    "            y_c, y_d, y_r = sub_country.loc[sub_country['Date']\n",
    "                                            == day_before, :].sum()[['confirmed', 'deaths', 'recovered']]\n",
    "\n",
    "            new_cases = t_c - y_c\n",
    "            new_deaths = t_d - y_d\n",
    "            new_recovery = t_r - y_r\n",
    "            new_cases_by_country.append(\n",
    "                {grouper: group, 'Date': current_date, 'New Cases': new_cases,\n",
    "                 'New Deaths': new_deaths, 'New Recovery': new_recovery})\n",
    "    return pd.DataFrame(new_cases_by_country)\n",
    "\n",
    "provence_df_per_day = per_x_cases('province',jhu_df_time)\n",
    "country_df_per_day = per_x_cases('country',jhu_df_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pprint\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# mapbox_style = \"mapbox://styles/plotlymapbox/cjvprkf3t1kns1cqjxuxmwixz\"\n",
    "mapbox_style = 'dark'\n",
    "mapbox_access_token = open('.mapbox_token').readlines()[0]\n",
    "\n",
    "# # Import from S3:\n",
    "# # merged_df = pd.read_csv(\n",
    "# #     'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/Merged_df.csv.gz', index_col=0).fillna('')\n",
    "# # per_day_stats_by_state = pd.read_csv(\n",
    "# #     'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/per_day_stats_by_state.csv.gz', index_col=0)\n",
    "# # per_day_stats_by_country = pd.read_csv(\n",
    "# #     'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/per_day_stats_by_country.csv.gz', index_col=0)\n",
    "# # per_day_stats_by_county = pd.read_csv(\n",
    "# #     'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/per_day_stats_by_county.csv.gz', index_col=0)\n",
    "\n",
    "\n",
    "# merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "# per_day_stats_by_state['Date'] = pd.to_datetime(\n",
    "#     per_day_stats_by_state['Date']).fillna('')\n",
    "# per_day_stats_by_country['Date'] = pd.to_datetime(\n",
    "#     per_day_stats_by_country['Date']).fillna('')\n",
    "# per_day_stats_by_county['Date'] = pd.to_datetime(\n",
    "#     per_day_stats_by_county['Date']).fillna('')\n",
    "date_mapper = pd.DataFrame(\n",
    "    jhu_df_time['Date'].unique(), columns=['Date'])\n",
    "date_mapper['Date_text'] = date_mapper['Date'].dt.strftime('%m/%d/%y')\n",
    "\n",
    "min_date = min(date_mapper.index)\n",
    "max_date = max(date_mapper.index)\n",
    "\n",
    "# centroid_country_mapper = merged_df.groupby(\n",
    "#     'Country/Region').apply(lambda x: x.sort_values('Cases')[::-1].iloc[0][['Lat', 'Long']])\n",
    "# centroid_country_mapper = {x[0]: {'Long': x[1]['Long'], 'Lat': x[1]['Lat']}\n",
    "#                            for x in centroid_country_mapper.iterrows()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_date = jhu_df_time.iloc[61]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapper = jhu_df_time[jhu_df_time['Date'] == official_date].groupby('country',as_index=False).apply(lambda x: x.sort_values('confirmed')[::-1].head(1)[['country','id','lat','lon']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapper['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df =jhu_df_time[jhu_df_time['Date'] == official_date].groupby('country',as_index=False).sum().merge(country_mapper,on=['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_df_time[jhu_df_time['Date'] == official_date].groupby('province',as_index=False).count().sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_df_time = jhu_df_time[jhu_df_time['province'].str.split(', ').str.len()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csbs_df['lat']= csbs_df['lat'].astype(float)\n",
    "csbs_df['lon']= csbs_df['lon'].astype(float)\n",
    "\n",
    "csbs_df.groupby(['county','state','lat','lon'],as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csbs_df[csbs_df['Date'] == date_mapper.iloc[0]['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_graph_state(date_int, group, metrics, figure):\n",
    "    # Get initial zoom and shit if the figure is already drawn\n",
    "    if not figure:\n",
    "        lat = 15.74\n",
    "        lon = -1.4\n",
    "        zoom = 1.6\n",
    "    elif \"layout\" in figure:\n",
    "        lat = figure[\"layout\"][\"mapbox\"]['center'][\"lat\"]\n",
    "        lon = figure[\"layout\"][\"mapbox\"]['center'][\"lon\"]\n",
    "        zoom = figure[\"layout\"][\"mapbox\"][\"zoom\"]\n",
    "\n",
    "    if not figure:\n",
    "        lat = 15.74\n",
    "        lon = -1.4\n",
    "        zoom = 1.6\n",
    "    elif \"layout\" in figure:\n",
    "        lat = figure[\"layout\"][\"mapbox\"]['center'][\"lat\"]\n",
    "        lon = figure[\"layout\"][\"mapbox\"]['center'][\"lon\"]\n",
    "        zoom = figure[\"layout\"][\"mapbox\"][\"zoom\"]\n",
    "\n",
    "    if 'cases' in metrics:\n",
    "        normalizer = 'confirmed'\n",
    "    elif 'active' in metrics:\n",
    "        normalizer = 'Active'\n",
    "    elif 'recovery' in metrics:\n",
    "        normalizer = 'recovered'\n",
    "    else:\n",
    "        normalizer = 'deahts'\n",
    "\n",
    "\n",
    "    official_date = date_mapper.iloc[date_int]['Date']\n",
    "    # print(date_int, official_date)\n",
    "\n",
    "    if group == 'country':\n",
    "        country_mapper = jhu_df_time[\n",
    "            jhu_df_time['Date'] == official_date].groupby(\n",
    "            'country',as_index=False).apply(lambda x: x.sort_values('confirmed')[::-1].head(1)[['country','id','lat','lon']])\n",
    "        sub_df =jhu_df_time[\n",
    "            jhu_df_time['Date'] == official_date].groupby('country',as_index=False).sum().merge(country_mapper,on=['country'])\n",
    "        sizeref = 2. * jhu_df_time.groupby(\n",
    "            ['Date', group]).sum().max()[normalizer] / (20 ** 2)\n",
    "\n",
    "    elif group == 'province':\n",
    "        sub_df = jhu_df_time[jhu_df_time[group] != '']\n",
    "        province_mapper = sub_df[\n",
    "            sub_df['Date'] == official_date].groupby(\n",
    "                group,as_index=False).apply(lambda x: x.sort_values('confirmed')[::-1].head(1)[[group,'id','lat','lon']])\n",
    "        sub_df =sub_df[\n",
    "            sub_df['Date'] == official_date].groupby(group,as_index=False).sum().merge(province_mapper,on=['province'])\n",
    "        sizeref = 2. * jhu_df_time.groupby(\n",
    "            ['Date', group]).sum().max()[normalizer] / (20 ** 2)\n",
    "\n",
    "    \n",
    "    elif group == 'county':\n",
    "        sub_df = csbs_df.groupby(['county','state','lat','lon'],as_index=False).sum()        \n",
    "        sub_df.rename({'cases':'confirmed'},axis=1,inplace=1)\n",
    "        sizeref = 2. * sub_df.max()[normalizer] / (20 ** 2)\n",
    "\n",
    "\n",
    "    sub_df['Active'] = sub_df['confirmed'] - sub_df['deaths'] - sub_df['recovered']\n",
    "    sub_df['Text_Cases'] = sub_df[group] + '<br>Total Cases at {} : '.format(\n",
    "        official_date.strftime('%m/%d/%y')) + sub_df['confirmed'].apply(lambda x: \"{:,}\".format(int(x)))\n",
    "    sub_df['Text_Death'] = sub_df[group] + '<br>Total Deaths at {} : '.format(\n",
    "        official_date.strftime('%m/%d/%y')) + sub_df['deaths'].apply(lambda x: \"{:,}\".format(int(x)))\n",
    "    sub_df['Text_Recover'] = sub_df[group] + '<br>Total Recoveries at {} : '.format(\n",
    "        official_date.strftime('%m/%d/%y')) + sub_df['recovered'].apply(lambda x: \"{:,}\".format(int(x)))\n",
    "\n",
    "    sub_df['Text_Active'] = sub_df[group] + '<br>Total Active at {} : '.format(\n",
    "        official_date.strftime('%m/%d/%y')) + sub_df['Active'].apply(lambda x: \"{:,}\".format(int(x)))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    if 'cases' in metrics:\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lon=sub_df['lon'].astype(float) +\n",
    "            np.random.normal(0, .02, len(sub_df['lon'])),\n",
    "            lat=sub_df['lat'].astype(float) +\n",
    "            np.random.normal(0, .02, len(sub_df['lat'])),\n",
    "            customdata=sub_df[group],\n",
    "            textposition='top right',\n",
    "            text=sub_df['Text_Cases'],\n",
    "            hoverinfo='text',\n",
    "            mode='markers',\n",
    "            name='cases',\n",
    "            marker=dict(\n",
    "                sizeref=sizeref,\n",
    "                sizemin=3,\n",
    "                size=sub_df['confirmed'],\n",
    "                color='yellow')))\n",
    "\n",
    "    if 'deaths' in metrics:\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lon=sub_df['Long'] +\n",
    "            np.random.normal(0, .02, len(sub_df['Long'])),\n",
    "            lat=sub_df['Lat'] +\n",
    "            np.random.normal(0, .02, len(sub_df['Lat'])),\n",
    "            customdata=sub_df[group],\n",
    "            textposition='top right',\n",
    "            text=sub_df['Text_Death'],\n",
    "            hoverinfo='text',\n",
    "            name='deaths',\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                sizeref=sizeref,\n",
    "                sizemin=3,\n",
    "                size=sub_df['deaths'],\n",
    "                color='red')))\n",
    "\n",
    "    if 'recovery' in metrics:\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lon=sub_df['Long'] +\n",
    "            np.random.normal(0, .02, len(sub_df['Long'])),\n",
    "            lat=sub_df['Lat'] +\n",
    "            np.random.normal(0, .02, len(sub_df['Lat'])),\n",
    "            customdata=sub_df[group],\n",
    "            textposition='top right',\n",
    "            text=sub_df['Text_Recover'],\n",
    "            hoverinfo='text',\n",
    "            name='recoveries',\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                sizeref=sizeref,\n",
    "                sizemin=3,\n",
    "                size=sub_df['recovered'],\n",
    "                color='green')))\n",
    "    if 'active' in metrics:\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lon=sub_df['Long'] +\n",
    "            np.random.normal(0, .02, len(sub_df['Long'])),\n",
    "            lat=sub_df['Lat'] +\n",
    "            np.random.normal(0, .02, len(sub_df['Lat'])),\n",
    "            customdata=sub_df[group],\n",
    "            textposition='top right',\n",
    "            text=sub_df['Text_Active'],\n",
    "            hoverinfo='text',\n",
    "            name='active',\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                sizeref=sizeref,\n",
    "                sizemin=3,\n",
    "                size=sub_df['Active'],\n",
    "                color='orange')))\n",
    "\n",
    "    if not metrics:\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lon=[],\n",
    "            lat=[]\n",
    "        ))\n",
    "    layout = dict(\n",
    "        title_text='The Corona is Coming',\n",
    "        autosize=True,\n",
    "        showlegend=True,\n",
    "        mapbox=dict(\n",
    "            accesstoken=mapbox_access_token,\n",
    "            style=mapbox_style,\n",
    "            zoom=zoom,\n",
    "            center=dict(lat=lat, lon=lon)\n",
    "        ),\n",
    "        hovermode=\"closest\",\n",
    "        margin=dict(r=0, l=0, t=0, b=0),\n",
    "        dragmode=\"pan\",\n",
    "        legend=dict(\n",
    "            x=0.92,\n",
    "            y=1,\n",
    "            traceorder=\"normal\",\n",
    "            font=dict(\n",
    "                family=\"sans-serif\",\n",
    "                size=14,\n",
    "                color=\"white\"\n",
    "            ),\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            # bordercolor=\"\",\n",
    "            # borderwidth=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(layout)\n",
    "    return fig\n",
    "\n",
    "fig = get_graph_state(61, 'county', ['cases'],'')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = state_df.merge(county_df,on=['Province/State'],suffixes=('','_county')) \n",
    "sub['Cases'] = sub['Cases'] + sub['Cases_county']\n",
    "sub['Deaths'] = sub['Deaths'] + sub['Deaths_county']\n",
    "sub['Recovery'] = sub['Deaths'] + sub['Recovery_county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 15.74\n",
    "lon = -1.4\n",
    "zoom = 1.6\n",
    "group = 'Province/State'\n",
    "sizeref = 2. * merged_df.groupby(\n",
    "        ['Date', group]).sum().max()['Cases'] / (20 ** 2)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattermapbox(\n",
    "    lon=sub_df['Long'] +\n",
    "    np.random.normal(0, .02, len(sub_df['Long'])),\n",
    "    lat=sub_df['Lat'] +\n",
    "    np.random.normal(0, .02, len(sub_df['Lat'])),\n",
    "    customdata=sub_df[group],\n",
    "    textposition='top right',\n",
    "    text=sub_df['Text_Cases'],\n",
    "    hoverinfo='text',\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizeref=sizeref,\n",
    "        sizemin=3,\n",
    "        size=sub_df['Cases'],\n",
    "        color='yellow')))\n",
    "    \n",
    "layout = dict(\n",
    "    title_text='The Corona is Coming',\n",
    "    autosize=True,\n",
    "    showlegend=False,\n",
    "    mapbox=dict(\n",
    "        accesstoken=mapbox_access_token,\n",
    "        style=mapbox_style,\n",
    "        zoom=zoom,\n",
    "        center=dict(lat=lat, lon=lon)\n",
    "    ),\n",
    "    #hovermode=\"closest\",\n",
    "    margin=dict(r=0, l=0, t=0, b=0),\n",
    "    dragmode=\"pan\",\n",
    ")\n",
    "\n",
    "fig.update_layout(layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sub_df['Cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
