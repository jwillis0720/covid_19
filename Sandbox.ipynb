{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load make_data.py\n",
    "from datetime import date\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import COVID19Py\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/csbs_df_Archive_3_31_2020.csv.gz\n",
      "Syncing Data\n",
      "Uploaded provence_df_per_day.csv.gz\n",
      "Uploaded jhu_df_time.csv.gz\n",
      "Uploaded country_df_per_day.csv.gz\n",
      "Uploaded Merged_df.csv.gz\n",
      "Uploaded csbs_df_Archive_3_28_2020.csv.gz\n",
      "Uploaded csbs_df_Archive_3_31_2020.csv.gz\n",
      "Uploaded csbs_df_Archive_03_25_2020.csv.gz\n",
      "Uploaded per_day_stats_by_country.csv.gz\n",
      "Uploaded jhu_df.csv.gz\n",
      "Uploaded csbs_df.csv.gz\n",
      "Uploaded csbs_df_Archive_3_26_2020.csv.gz\n",
      "Uploaded per_day_stats_by_state.csv.gz\n",
      "Uploaded per_day_stats_by_county.csv.gz\n",
      "Uploaded csbs_df_Archive_3_30_2020.csv.gz\n",
      "Uploaded combined_time_scales.csv.gz\n"
     ]
    }
   ],
   "source": [
    "%%writefile make_data.py\n",
    "from datetime import date\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import COVID19Py\n",
    "import pandas\n",
    "\n",
    "# Cancel copy warnings of pandas\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=pd.core.common.SettingWithCopyWarning)\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(\n",
    "            file_name, bucket, object_name,  ExtraArgs={'ACL': 'public-read'})\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def parse_timeline_date_api_json(json, source):\n",
    "    for_pandas = []\n",
    "\n",
    "    status_dfs = []\n",
    "    if 'timelines' not in json['locations'][0].keys():\n",
    "        raise ReferenceError('This is not a timeline json')\n",
    "\n",
    "    dates = []\n",
    "    timestamp = []\n",
    "    confirmed = []\n",
    "    deaths = []\n",
    "    location = []\n",
    "    ids = []\n",
    "    lats = []\n",
    "    lons = []\n",
    "    province = []\n",
    "    country_code = []\n",
    "    country = []\n",
    "    county = []\n",
    "    for location in json['locations']:\n",
    "        d = list(location['timelines']['confirmed']['timeline'].keys())\n",
    "        size_len = len(d)\n",
    "        confirmed_ = list(location['timelines']\n",
    "                          ['confirmed']['timeline'].values())\n",
    "        deaths_ = list(location['timelines']['deaths']['timeline'].values())\n",
    "        timestamp += pandas.to_datetime(d)\n",
    "        assert(len(confirmed_) == len(deaths_) == size_len)\n",
    "        ids += [location['id']]*size_len\n",
    "        lats += [location['coordinates']['latitude']]*size_len\n",
    "        lons += [location['coordinates']['longitude']]*size_len\n",
    "        province += [location['province']]*size_len\n",
    "        country_code += [location['country_code']]*size_len\n",
    "        country += [location['country']]*size_len\n",
    "        if 'county' in location.keys():\n",
    "            county += [location['county']]*size_len\n",
    "        else:\n",
    "            county += ['']*size_len\n",
    "        confirmed += confirmed_\n",
    "        deaths += deaths_\n",
    "\n",
    "    # print(len(lats),len(lons),len(timestamp))\n",
    "    df = pandas.DataFrame({'id': ids, 'lat': lats, 'lon': lons, 'Timestamp': timestamp, 'Date': \"\", 'province': province,\n",
    "                           'country_code': country_code, 'country': country, 'county': county, 'confirmed': confirmed, 'deaths': deaths})\n",
    "    df['source'] = source\n",
    "    df['Date'] = df['Timestamp'].dt.date\n",
    "    df['Date'] = pandas.to_datetime(df['Date'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_current_date_api_json(json, source):\n",
    "    for_pandas = []\n",
    "    confirmed = []\n",
    "    deaths = []\n",
    "    recovered = []\n",
    "    for location in json['locations']:\n",
    "        entry = {\n",
    "            'id': location['id'],\n",
    "            'lat': location['coordinates']['latitude'],\n",
    "            'lon': location['coordinates']['longitude'],\n",
    "            'Timestamp': pandas.to_datetime(location['last_updated']),\n",
    "            'Date': \"\",\n",
    "            'province': location['province'],\n",
    "            'country_code': location['country_code'],\n",
    "            'country': location['country'],\n",
    "            'county': '',\n",
    "            'confirmed': location['latest']['confirmed'],\n",
    "            'deaths': location['latest']['deaths']}\n",
    "        if 'county' in location.keys():\n",
    "            entry['county'] = location['county']\n",
    "        if 'state' in location.keys():\n",
    "            entry['state'] = location['state']\n",
    "        entry['source'] = source\n",
    "        for_pandas.append(entry)\n",
    "    df = pd.DataFrame(for_pandas)\n",
    "    df['Date'] = df['Timestamp'].dt.date\n",
    "    df['Date'] = pandas.to_datetime(df['Date'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def per_x_cases(grouper, df):\n",
    "    new_cases_by_country = []\n",
    "    date_mapper = pd.DataFrame(\n",
    "        df['Date'].unique(), columns=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "    dates = date_mapper['Date']\n",
    "    # print(dates)\n",
    "    sub_group = df[df[grouper] != \"\"]\n",
    "    groupers = sub_group[grouper].unique()\n",
    "\n",
    "    for group in groupers:\n",
    "        sub_country = sub_group[sub_group[grouper] == group]\n",
    "        new_cases_by_country.append(\n",
    "            {grouper: group, 'Date': dates[0],\n",
    "             'New Cases': sub_country.loc[sub_country['Date'] == dates[0], 'confirmed'].sum(),\n",
    "             'New Deaths': 0})\n",
    "        for date_index in range(1, len(dates)):\n",
    "            current_date = dates[date_index]\n",
    "            day_before = dates[date_index-1]\n",
    "            # print(current_date,day_before)\n",
    "            t_c, t_d = sub_country.loc[sub_country['Date']\n",
    "                                       == current_date, :].sum()[['confirmed', 'deaths']]\n",
    "\n",
    "            y_c, y_d = sub_country.loc[sub_country['Date']\n",
    "                                       == day_before, :].sum()[['confirmed', 'deaths']]\n",
    "\n",
    "            new_cases = t_c - y_c\n",
    "            new_deaths = t_d - y_d\n",
    "            if new_cases < 0:\n",
    "                new_cases = 0\n",
    "            if new_deaths < 0:\n",
    "                new_deaths = 0\n",
    "                print(current_date, day_before, t_c, y_c, group)\n",
    "                # return sub_country\n",
    "            new_cases_by_country.append(\n",
    "                {grouper: group, 'Date': current_date, 'New Cases': new_cases,\n",
    "                 'New Deaths': new_deaths})\n",
    "    return pd.DataFrame(new_cases_by_country)\n",
    "\n",
    "\n",
    "def backfill_new_counties(df):\n",
    "    date_range = pd.date_range(pd.to_datetime(\n",
    "        '2020-1-22'), df['Date'].max(), freq='1D')\n",
    "    unique_group = ['country', 'province', 'county']\n",
    "    gb = df.groupby(unique_group)\n",
    "    sub_dfs = []\n",
    "    for g in gb.groups:\n",
    "        sub_df = gb.get_group(g)\n",
    "        sub_df = (\n",
    "            sub_df.groupby('Date')\n",
    "            .head(1)\n",
    "            .set_index('Date')\n",
    "            .reindex(date_range)\n",
    "            .fillna(dict.fromkeys(['confirmed', 'deaths'], 0))\n",
    "            .bfill()\n",
    "            .ffill()\n",
    "            .reset_index()\n",
    "            .rename({'index': 'Date'}, axis=1))\n",
    "        sub_df['Date_text'] = sub_df['Date'].dt.strftime('%m/%d/%y')\n",
    "        sub_df['Timestamp'] = pd.to_datetime(sub_df['Date'], utc=True)\n",
    "        sub_dfs.append(sub_df)\n",
    "    all_concat = pd.concat(sub_dfs)\n",
    "    assert((all_concat.groupby(['province', 'country', 'county']).count() == len(\n",
    "        date_range)).all().all())\n",
    "    return all_concat\n",
    "\n",
    "\n",
    "# Get current streaming API\n",
    "covid19_csbs = COVID19Py.COVID19(data_source=\"csbs\").getAll(timelines=True)\n",
    "covid19_jhu = COVID19Py.COVID19(data_source=\"jhu\").getAll(timelines=True)\n",
    "\n",
    "\n",
    "# Gets current values\n",
    "jhu_current = parse_current_date_api_json(covid19_jhu, 'JHU')\n",
    "csbs_current = parse_current_date_api_json(covid19_csbs, 'CSBS')\n",
    "\n",
    "# Gets timeline values\n",
    "jhu_time = parse_timeline_date_api_json(covid19_jhu, 'JHU')\n",
    "\n",
    "# Get Date text\n",
    "csbs_current['Date_text'] = csbs_current['Timestamp'].dt.strftime('%m/%d/%y')\n",
    "jhu_time['Date_text'] = jhu_time['Timestamp'].dt.strftime('%m/%d/%y')\n",
    "jhu_current['Date_text'] = jhu_current['Timestamp'].dt.strftime('%m/%d/%y')\n",
    "\n",
    "\n",
    "# Lets get the current one\n",
    "csbs_df_past = pd.read_csv(\n",
    "    'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/csbs_df.csv.gz', index_col=0)\n",
    "csbs_df_past['Timestamp'] = pd.to_datetime(csbs_df_past['Date'])\n",
    "csbs_df_past['Date'] = csbs_df_past['Timestamp'].dt.date\n",
    "csbs_df_past['Date'] = pandas.to_datetime(csbs_df_past['Date'])\n",
    "csbs_df_past['Date_text'] = csbs_df_past['Timestamp'].dt.strftime('%m/%d/%y')\n",
    "\n",
    "csbs_current = csbs_current.drop('id', axis=1)\n",
    "# sort for columns\n",
    "csbs_df_past = csbs_df_past[csbs_current.columns]\n",
    "\n",
    "# This should be okay since we stored it this way\n",
    "csbs_df_past = csbs_df_past.sort_values('confirmed')[::-1].groupby(\n",
    "    ['lat', 'lon', 'Date', 'province', 'country_code', 'country', 'county', 'source']).head(1)\n",
    "\n",
    "# Before we merge lets write out todays date\n",
    "today = date.today()\n",
    "csbs_current.to_csv(\n",
    "    'Data/csbs_df_Archive_{}_{}_{}.csv.gz'.format(today.month, today.day, today.year))\n",
    "print('Data/csbs_df_Archive_{}_{}_{}.csv.gz'.format(today.month, today.day, today.year))\n",
    "\n",
    "# # Lets add together the past and current\n",
    "csbs_new = pd.concat([csbs_df_past, csbs_current])\n",
    "\n",
    "# Finally we can backfill\n",
    "\n",
    "#Lets drop the ones that don't have \n",
    "csbs_new['province'] = csbs_new['province'].fillna('Unincorporated')\n",
    "csbs_new = backfill_new_counties(csbs_new)\n",
    "\n",
    "\n",
    "# # lets ensure that csbs_new has just one date\n",
    "csbs_new = csbs_new.sort_values('confirmed').groupby(\n",
    "    ['Date', 'province', 'country_code', 'country', 'county', 'source']).head(1)\n",
    "csbs_new['Timestamp'] = pandas.to_datetime(csbs_new['Timestamp'], utc=True)\n",
    "csbs_new['Date_text'] = csbs_new['Timestamp'].dt.strftime('%m/%d/%y')\n",
    "\n",
    "jhu_time = jhu_time.drop('id', axis=1)\n",
    "jhu_current = jhu_current.drop('id', axis=1)\n",
    "csbs_new = csbs_new[jhu_time.columns]\n",
    "jhu_current = jhu_current[jhu_time.columns]\n",
    "\n",
    "assert(\n",
    "    (jhu_time.groupby(['Date', 'country', 'province']).count() == 1).all().all())\n",
    "assert((csbs_new.groupby(\n",
    "    ['Date', 'country', 'province', 'county']).count() == 1).all().all())\n",
    "assert((jhu_current.groupby(\n",
    "    ['Date', 'country', 'province', 'county']).count() == 1).all().all())\n",
    "assert(list(jhu_current.columns) == list(csbs_new.columns))\n",
    "\n",
    "assert((csbs_new.groupby(['country', 'province', 'county']).count() == len(\n",
    "    csbs_new['Date'].unique())).all().all())\n",
    "\n",
    "# Lets Write everything out\n",
    "jhu_current.to_csv('Data/jhu_df.csv.gz', compression='gzip')\n",
    "\n",
    "# Write Out Time Course\n",
    "jhu_time.to_csv('Data/jhu_df_time.csv.gz', compression='gzip')\n",
    "\n",
    "# Write out Current CSV\n",
    "csbs_new.to_csv('Data/csbs_df.csv.gz', compression='gzip')\n",
    "\n",
    "print('Syncing Data')\n",
    "ea = ExtraArgs = {'ACL': 'public-read'}\n",
    "gs = glob.glob('Data/*.csv.gz')\n",
    "for file in gs:\n",
    "    upload_file(file, 'jordansdatabucket', os.path.join(\n",
    "        'covid19data', os.path.basename(file)))\n",
    "    print(\"Uploaded \" + os.path.basename(file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_csbs= COVID19Py.COVID19(data_source=\"csbs\").getAll(timelines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>province</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>county</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>source</th>\n",
       "      <th>Date_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-03-30 00:00:00</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>03/30/20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat      lon            Timestamp       Date province country_code  \\\n",
       "68  41.2718 -112.141  2020-03-30 00:00:00 2020-03-30      NaN           US   \n",
       "\n",
       "   country        county  confirmed  deaths source Date_text  \n",
       "68      US  WarrenWarren        2.0     0.0   CSBS  03/30/20  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csbs_new[csbs_new['county'] == 'WarrenWarren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>province</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>county</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>source</th>\n",
       "      <th>Date_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-01-22 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>01/22/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-01-23 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>01/23/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-01-24 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>01/24/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-01-25 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>01/25/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-01-26 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>01/26/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-03-27 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>03/27/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-03-28 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>03/28/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-03-29 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>03/29/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-03-30 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>03/30/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>41.2718</td>\n",
       "      <td>-112.141</td>\n",
       "      <td>2020-03-31 00:00:00+00:00</td>\n",
       "      <td>Unincorporated</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>WarrenWarren</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CSBS</td>\n",
       "      <td>03/31/20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      lat      lon                 Timestamp        province  \\\n",
       "0  2020-01-22  41.2718 -112.141 2020-01-22 00:00:00+00:00  Unincorporated   \n",
       "1  2020-01-23  41.2718 -112.141 2020-01-23 00:00:00+00:00  Unincorporated   \n",
       "2  2020-01-24  41.2718 -112.141 2020-01-24 00:00:00+00:00  Unincorporated   \n",
       "3  2020-01-25  41.2718 -112.141 2020-01-25 00:00:00+00:00  Unincorporated   \n",
       "4  2020-01-26  41.2718 -112.141 2020-01-26 00:00:00+00:00  Unincorporated   \n",
       "..        ...      ...      ...                       ...             ...   \n",
       "65 2020-03-27  41.2718 -112.141 2020-03-27 00:00:00+00:00  Unincorporated   \n",
       "66 2020-03-28  41.2718 -112.141 2020-03-28 00:00:00+00:00  Unincorporated   \n",
       "67 2020-03-29  41.2718 -112.141 2020-03-29 00:00:00+00:00  Unincorporated   \n",
       "68 2020-03-30  41.2718 -112.141 2020-03-30 00:00:00+00:00  Unincorporated   \n",
       "69 2020-03-31  41.2718 -112.141 2020-03-31 00:00:00+00:00  Unincorporated   \n",
       "\n",
       "   country_code country        county  confirmed  deaths source Date_text  \n",
       "0            US      US  WarrenWarren        0.0     0.0   CSBS  01/22/20  \n",
       "1            US      US  WarrenWarren        0.0     0.0   CSBS  01/23/20  \n",
       "2            US      US  WarrenWarren        0.0     0.0   CSBS  01/24/20  \n",
       "3            US      US  WarrenWarren        0.0     0.0   CSBS  01/25/20  \n",
       "4            US      US  WarrenWarren        0.0     0.0   CSBS  01/26/20  \n",
       "..          ...     ...           ...        ...     ...    ...       ...  \n",
       "65           US      US  WarrenWarren        0.0     0.0   CSBS  03/27/20  \n",
       "66           US      US  WarrenWarren        0.0     0.0   CSBS  03/28/20  \n",
       "67           US      US  WarrenWarren        0.0     0.0   CSBS  03/29/20  \n",
       "68           US      US  WarrenWarren        2.0     0.0   CSBS  03/30/20  \n",
       "69           US      US  WarrenWarren        0.0     0.0   CSBS  03/31/20  \n",
       "\n",
       "[70 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csbs_three[csbs_three['province'] == 'Unincorporated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
